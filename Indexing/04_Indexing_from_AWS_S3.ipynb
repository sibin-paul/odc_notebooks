{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf70f2fa",
   "metadata": {},
   "source": [
    "# Indexing data from Amazon (AWS S3)\n",
    "The purpose of this notebook is to explain the indexing of free publicly accessible notebooks available in Amazon's cloud storage service S3 buckets. This allows geospatial data stored on the cloud to be indexed provided the machine with datacube setup has internet access. Most of the data on S3 buckets are available to use freely and the requester need not even have an AWS account to do so. \n",
    "\n",
    "Indexing from cloud storages is encouraged as this means that user’s disk usage is minimised and he/she can access any temporal dataset(in most cases) of any geographical location of a specific product.\n",
    "## Description\n",
    "The topics covered in this notebook include\n",
    "* [Prerequisites for Cloud Indexing](#Prerequisites)\n",
    "* [S3 Indexing Process](#S3-Indexing-Process)\n",
    "* [Data on Amazon S3](#Data-on-Amazon-S3)\n",
    "* [Recommended Next Steps](#Recommended-Next-Steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb0ae0",
   "metadata": {},
   "source": [
    "**Note:** *The commands are meant to be run on a command line interface(like terminal in Linux). But in JupyterHub Notebook you can run the commands by placing a `!` before the command.*\n",
    "\n",
    "`! <command>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da64da",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Options currently exist that allow for a user to store, index, and retrieve data from cloud object stores, such as Amazon S3 buckets, using the open ODC. There are a few additional requirements outline below. With the help of python package [odc_apps_dc_tools](https://github.com/opendatacube/odc-tools/tree/develop/apps/dc_tools).\n",
    "users can index data available from S3 buckets.\n",
    "\n",
    "The python package `odc-apps-dc-tools` can be installed using command:\n",
    "\n",
    "`pip install odc-apps-dc-tools`\n",
    "\n",
    "***Note: This package has already been installed in the JupyterHub environment you are currently using***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08d1ec",
   "metadata": {},
   "source": [
    "## Data on Amazon S3\n",
    "Regarding data on S3 buckets checkout the following links\n",
    "* [Registry of Open Data on AWS](https://registry.opendata.aws/)\n",
    "* [Digital Earth Australia - Public Data](https://data.dea.ga.gov.au/?prefix=)\n",
    "* [Digital Earth Africa](https://explorer.dev.digitalearth.africa/products/alos_palsar_mosaic/extents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c1b25",
   "metadata": {},
   "source": [
    "## The `s3-to-dc` command\n",
    "The `s3-to-dc` command is used to index the datasets available in the S3 buckets. Use the command in by following the below syntax\n",
    "\n",
    "`s3-to-dc [OPTIONS] [URL] [PRODUCT NAME]`\n",
    " * The URL points to the product defintion(in yaml, json formats in the cloud storage\n",
    " * The PRODUCT NAME refers to the name of the product the dataset is a part of\n",
    " * The `s3-to-dc` command line tool allow you to specify some options if required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34993d",
   "metadata": {},
   "source": [
    "##### The cell below runs the help command on the s3-to-dc app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3bfe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: s3-to-dc [OPTIONS] URI PRODUCT\n",
      "\n",
      "  Iterate through files in an S3 bucket and add them to datacube\n",
      "\n",
      "Options:\n",
      "  --skip-lineage                  Default is not to skip lineage. Set to skip\n",
      "                                  lineage altogether.\n",
      "\n",
      "  --fail-on-missing-lineage / --auto-add-lineage\n",
      "                                  Default is to fail if lineage documents not\n",
      "                                  present in the database. Set auto add to try\n",
      "                                  to index lineage documents.\n",
      "\n",
      "  --verify-lineage                Default is no verification. Set to verify\n",
      "                                  parent dataset definitions.\n",
      "\n",
      "  --stac                          Expect STAC 1.0 metadata and attempt to\n",
      "                                  transform to ODC EO3 metadata.\n",
      "\n",
      "  --absolute                      Use absolute paths from the STAC document.\n",
      "  --update                        If set, update instead of add datasets.\n",
      "  --update-if-exists              If the dataset or product already exists,\n",
      "                                  update it instead of skipping it.\n",
      "\n",
      "  --allow-unsafe                  Allow unsafe changes to a dataset. Take\n",
      "                                  care!\n",
      "\n",
      "  --skip-check                    Assume file exists when listing exact file\n",
      "                                  rather than wildcard.\n",
      "\n",
      "  --no-sign-request               Do not sign AWS S3 requests.\n",
      "  --request-payer                 Needed when accessing requester pays public\n",
      "                                  buckets.\n",
      "\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "! s3-to-dc --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5df538",
   "metadata": {},
   "source": [
    "***Note***:\n",
    "* *Use the `--stac` option if the metadata on the S3 bucket is in STAC format*\n",
    "* *Money is charged when accessing requester pays public buckets*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042d126",
   "metadata": {},
   "source": [
    "## S3 Indexing Process\n",
    "For this example we will be indexing Digital Earth Australia’s public data bucket, which you can browse at [data.dea.ga.gov.au](https://data.dea.ga.gov.au/).\n",
    "\n",
    "Run the two lines below, the first will add the product definition for the Landsat Geomedian product and the second will add all of the Geomedian datasets. This will take some time, but will add a continental product to the Datacube setup.\n",
    "\n",
    "1. `datacube product add https://data.dea.ga.gov.au/geomedian-australia/v2.1.0/product-definition.yaml`\n",
    "\n",
    "2. `s3-to-dc --no-sign-request 's3://dea-public-data/geomedian-australia/v2.1.0/L8/**/*.yaml' ls8_nbart_geomedian_annual`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcdc37",
   "metadata": {},
   "source": [
    "##### Indexing the product definition using the `datacube` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57078856",
   "metadata": {},
   "outputs": [],
   "source": [
    "! datacube product add https://data.dea.ga.gov.au/geomedian-australia/v2.1.0/product-definition.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931abf06",
   "metadata": {},
   "source": [
    "##### Indexing the datasets using the `s3-to-dc` command available through the [odc_apps_dc_tools](https://github.com/opendatacube/odc-tools/tree/develop/apps/dc_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! s3-to-dc --no-sign-request 's3://dea-public-data/geomedian-australia/v2.1.0/L8/**/*.yaml' ls8_nbart_geomedian_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34e0b0",
   "metadata": {},
   "source": [
    "## Recommended Next Steps\n",
    "Loading the datasets and plotting satellite images come after the process of indexing. Therefore we recommend you to go through the indexing notebooks to understand the different steps involved and different sources from where data could be indexed. Click on the links which will take you to the respective notebooks.\n",
    "\n",
    "1. [Introduction to ODC Indexing](01_Introduction_to_ODC_Indexing.ipynb)\n",
    "2. [Indexing Product Definition](02_Indexing_Product_Definition.ipynb)\n",
    "3. [Indexing from Local File System](03_Indexing_from_Local_File_System.ipynb)\n",
    "4. **Indexing from Amazon - AWS S3(This Notebook)**\n",
    "5. [Indexing using STAC](05_Indexing_using_STAC.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
